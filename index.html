<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="./css/style.css" />
    <link rel="shortcut icon" href="./img/kc-logov2.ico" type="image/x-icon" />
    <title>Kókány Corporations</title>
  </head>
  <body>
    <div class="container">
      <div class="search">
        <div class="logo-header">
          <img src="./img/kc-logov2.png" alt="Kókány Corporations Logo" />
          <h3>Kókány Corporations</h3>
          <h5>Team Description Material</h5>
        </div>
        <div class="links" id="toc">
        </div>
      </div>
      <div class="main-text">
        <div>
          <h1>Logisctical Informations</h1>
          <h3><b>Team name:</b> Kókány Corporations</h3>
          <h3>
            <b>Organistaion:</b> Nyíregyházi SZC Széchenyi István Technikum és
            Kollágium
          </h3>
          <h3><b>Country:</b> Hungary</h3>
          <h3><b>Mentor:</b> Mr. Bakti András</h3>
          <h3><b>Contact Person:</b> Mr. Bakti András</h3>
          <h3><b>Phone:</b> +3630/252-3931</h3>
          <h3><b>Email:</b> info@robottep.hu</h3>
          <h3>
            <b>Website:</b>
            <a href="https://robottep.hu" target="_blank"
              >Our mentor's website</a
            >
          </h3>
          <p>
            Our team consist of 4 ambitious members. We created this team in
            2022 since then we tried our best to participate in various
            competitions and challenge ourself to hardwer and more complicated
            porjects. We all plan to go and study close to this subject and
            enviroment. Most of us is in our last year and soon will be brought
            to a decision of our future. We all plan to attend to universities
            and learn more and more. We are good friends with each other and we
            try to help out whenever we can. It is a mutual relationship between
            us team mebers. If one of us don't understand the concepts that one
            thought of we discuss it and move forward with the development.
            Development is a fun and exhousting activity but the process is what
            important the fails and rebuilding is what it makes it soo much fun
            too.
          </p>
        </div>
        <div class="margintop">
          <h1>Members of the team</h1>
          <div class="introduc">
            <img src="img/pfp6.jpg" alt="Our mentor pfp" />
            <h2>Mr. Bakti András</h2>
            <h4>Role: Mentor</h4>
            <p>
              Mr. Bakti András is our mentor. He focuses on making sponsorship
              deals and the process of the contracts. He's also giving us
              advives about the robot's pyhscical aspects and he will be
              responsible for our safety in the Competition. He's on of the
              teacher in our school.
            </p>
          </div>
          <div class="introduc">
            <img src="img/pfp1.jpg" alt="Máté" />
            <h2>Mester Máté</h2>
            <h4>Role: Hardware</h4>
            <p>
              Máté focuses on the mechanical aspect of our robot, he works on
              the design and assembly of the robot. He designs the main body,
              and he designed our latest 3D printed wheels. He also deals with
              the logistical issues for the team. This is his third year with
              the team. Mate took intrest in mechanical engineering. He's 18
              years old.
            </p>
          </div>
          <div class="introduc">
            <img src="img/pfp3.jpg" alt="Robi" />
            <h2>Tran Duy Dat</h2>
            <h4>Role: Hardware</h4>
            <p>
              Dat also focuses on the mechanical aspect of the robot, he designs
              parts using CAD software and helps with the assembly of parts. He
              designed our custom support arm which enables the robot for
              climbing into high surfaces. He's 18 years old as well and he took
              intrest in mechanical engineering and web development. He's the
              one who developped the TDM as a website and designed the team
              shirt. He's also in his third year in this team.
            </p>
          </div>
          <div class="introduc">
            <img src="img/pfp4.jpg" alt="Bence" />
            <h2>Vadász Bence</h2>
            <h4>Role: Hardware</h4>
            <p>
              Bence is the newest and youngest member of our team, he helps out
              with the hardware related aspects of our robot and the assembly.
              He's currently trying to understand the robot itself. He's also
              the one who designed our team's logo.
            </p>
          </div>
          <div class="introduc">
            <img src="img/pfp5.jpg" alt="Zsolt" />
            <h2>Vadász Zsolt</h2>
            <h4>Role: Programmer</h4>
            <p>
              Zsolt is responsible for the software of the robot. He's the one
              who programmed the robot movement and arm functionality as well as
              the image recognition software. He's intrested in micro controller
              programming as well as the manufacturing process of these
              controllers. He's 19 years old.
            </p>
          </div>
        </div>
        <div class="margintop">
          <h1>Competitions we attended so far</h1>
          <div class="comps-box">
            <h3>MIRK (Hungarian Youth Robo Cup) year 2024</h3>
            <img
              src="./img/firstPlace1.jpg"
              alt="Picture of the 2024 MIRK RMRC robot"
            />
            <p>
              MIRK 2024: This was our third competition and our third win with
              this we are three times Hungarian champions. The biggest
              difference is our robot's build. Firstly we moved our motors
              inline with our electronics with this the height of the robot
              decreased and the wheight optimalised. We also switched the energy
              source instead of using 18650 litium batteries we used a Parkside
              20V drill battery however with the more voltage we needed two
              stepdowns instead of one. We also switched back to Motozero
              instead of the L298n motor driver which helped us with the inner
              space however the downside of the Motozero was the heat. We needed
              to install a fan and put on a heatsink to prevent the driver to
              overheat. We also used servo motors instead of stepper motors. We
              also realized that the 3D printed parts weren't durable so we
              found some metal cases and build a arm out of that. The controll
              of the arm was done with the PCA9868 arduino board. We also finxed
              the video latency and intalled a second camera for the back view
              with this we used two person to operate. One was driving the main
              robot and one was checking with him the camreras. We brought a
              secondary monitor to see the camera output better.
            </p>
          </div>
          <div class="comps-box">
            <h3>Previous RoboCup23</h3>
            <img
              src="img/robocup23.jpg"
              alt="Picture of the robot in RoboCup23"
            />
            <p>
              RoboÍCup23, Bordeaux France. The first international competition
              we participate was the RoboCup23 last year. The first thing we
              wanted to do was the arm. The mistake from MIRK(Hungarian Youth
              Robo Cup) was that we couldn't use our arm and it prevented us
              from getting critical points so that time we designed an arm which
              used 28-BYJ stepper motors. We also tried making a custom PCB that
              would provide us with powering all 8 stepper motors and also
              controlling them. Unfortunately both the PCB and stepper arm
              didn't work. We forgot a crucial part when designing the robot
              arm. How much wheight can the motors hold on a certian distance?
              Well in this case not a lot. When we gave 5V(This is the supported
              voltage of the motor) the arm couldn't lift itself up, but when we
              connected on the 12V it was enough to start moving and functioning
              however the energy consumption also skyrocked. On the motor part
              the socket for the motor was 3D printed, but the rough arena and
              the conditions were too much for the basic L shape motor holder.
              It broke in the middle of the competition. One of the bigger
              challenge was the camera streaming and the image recognition.
              Zsolti spent a great amount of time on debugging and developping.
              The software was written in C and there wasn't a library for the
              purpose we wanted. All in all the competition was really helpull
              and we learned a lot from it.
            </p>
          </div>
          <div class="comps-box">
            <h3>MIRK (Hungarian Youth Robo Cup) year 2023</h3>
            <img
              src="./img/firstPlace2.jpg"
              alt="Picture of the 2023 MIRK RMRC robot"
            />
            <p>
              The second MIRK was held in 2023 where we improved our motors and
              wheels. We used bigger wheels which helped us in the uneven parts
              of the arena. We also swhiched the robot arm that time we wanted
              to use a custom arm and we tried our best to make one with the
              separate parts we found in the workspace. Unfortunately the arm
              didn't work it couldn't lift itself up. We also got better motors
              which were half metal geared and half plastic geared which was a
              big improvment because it didn't break this time. After winning
              the championship our mentor Mr. Bakti András mentioned the
              RoboCup23 and asked us if we want to participate in it and we said
              yes and the preparations for the RoboCup begun.
            </p>
          </div>
          <div class="comps-box">
            <h3>MIRK (Hungarian Youth Robo Cup) year 2022</h3>
            <img
              src="img/firstPlace3.jpg"
              alt="Picture of the 2022 MIRK RMRC robot"
            />
            <p>
              Our first competition was in 2022 march. As you can see the robot
              was made out of 2 3mm plexi board which was cut with laser. The
              arm was controlled with a Raspberry Pi 4 connected to a PCA9868
              servo controller. We used 3 cells which provided 12V which we
              converted down to 5V to the Raspberry. The motors was controlled
              with a Motozero and the motors were running on 12V. unfortunately
              the motors broke in some parts of the arena and we couldn't reused
              them in the following year.
            </p>
          </div>
        </div>
        <div class="margintop">
          <h1>Software</h1>
          <div class="simplify">
            <h2>Simplifying our software with device trees</h2>
            <p>
              Last year we used a library called
              <a
                href="https://git.kernel.org/pub/scm/utils/i2c-tools/i2c-tools.git/about/"
              >
                libi2c</a
              >
              to control some of our stepper motors using an external
              <a href="https://www.microchip.com/en-us/product/MCP23017"
                >MCP23017 GPIO expander</a
              >. Since then we have switched to using servos for our robotic
              arm. We also wanted to make our software more flexible, and the
              best way to do this was ripping out the useless code and using the
              right tools for the job.
            </p>
            <p>
              While programs are allowed to just use libi2c, it adds (often
              redundant) extra code to a project. The Kernel actually has
              drivers for a lot of common ICs such as GPIO expanders—like the
              MCP23017 we used—or PWM controllers like the
              <a href="https://www.adafruit.com/product/815">PCA9685</a>.
            </p>
            <p>
              One improvement we've made was deleting the I2C parts from our
              code, and instead using the
              <a
                href="https://elixir.bootlin.com/linux/latest/source/drivers/pwm/pwm-pca9685.c"
                >kernel driver</a
              >
              instead. This is great because we can just interact with the
              userspace PWM API via something like
              <a href="https://github.com/zsoltiv/libhwpwm/tree/master"
                >libhwpwm</a
              >
              (more on that later).
            </p>
            <p>
              To achieve this, we wrote a
              <a
                href="https://github.com/zsoltiv/kokanybot/blob/master/overlays/kokanyservoctl.dts"
                >device tree overlay</a
              >. Device tree overlays are kind of like patch files for
              <a
                href="https://www.kernel.org/doc/html/latest/devicetree/usage-model.html"
                >device trees</a
              >. This file allows us to tell Linux what chips are available on
              certain I2C addresses.
            </p>
          </div>
          <div class="tcpToUdp">
            <h2>Switching from TCP to UDP</h2>
            <p>
              Robotics taught us just how fragile computers are when subjected
              to harsher environments. Short circuits may occur, components
              might get knocked against a robot's frame, boards can overheat,
              all of which can result in a robot rebooting or shutting down
              entirely.
            </p>
            <p>
              In our previous competitions, we have <i>always</i> had faults
              like this occur. If things were going too well, then our UTP cable
              slipped out of our control station's Ethernet port. In these
              cases, we almost always had to reboot our robot and do the
              software side of the setup again and then reconnect, wasting
              precious time.
            </p>
            <p>
              Mitigating these issues while sticking with TCP sockets would mean
              having to handle potential connection issues every time we
              send/receive data. Instead of doing that, we've been making steady
              progress to switch over to UDP, which is a different
              communications protocol. As of now, the code which receives
              keyboard input uses no TCP sockets, it's all stateless.
            </p>
            <p>
              The main advantage of UDP compared to TCP is its statelessness:
              networked programs do not need to
              <code>connect()</code>, <code>listen()</code> nor
              <code>accept()</code>, which also means no need to track clients;
              you create a socket, and send/receive data over it using
              <code>sendto()</code> and <code>recvfrom()</code>. This eliminates
              the need for handling reconnections.
            </p>
            <p>
              The main downsides of UDP are that it does not guarantee data
              packets arriving in the correct order nor does it guarantee that
              they arrive <i>at all</i>. This is not really an issue for us,
              since the entire network is point-to-point with no more than two
              hosts, and we have yet to experience any problems.
            </p>
          </div>
          <div class="gasRemoving">
            <h2>Removing gas sensing code</h2>
            <p>
              The rulebook's
              <a
                href="https://oarkit.intelligentrobots.org/home/wp-content/uploads/2023/10/RoboCupRescue-RMRC-2024-Rulebook-working-draft-2023-10-15.pdf"
                >latest draft</a
              >
              does not mention CO<sub>2</sub> sensing, therefore we've removed
              all code related to it. If a later draft brings it back, we can
              just reuse a previous commit, as we've often done during
              development.
            </p>
          </div>
          <div class="image-recognision">
            <h2>4.1 Training an object detection model</h2>

            <p>
              Last time, one of the most challenging aspects of the competition
              was the object detection feature robots needed. Back in Bordeaux,
              we failed to detect anything and got 0 points for object
              detection. We definitely needed to improve on that.
            </p>

            <p>
              Firstly, we found a
              <a
                href="https://universe.roboflow.com/new-workspace-xqnz7/rmrc-dqa9p"
                >large enough dataset</a
              >
              on the internet (1k+ photos), which was a godsend because it
              spared us from having to manually take pictures and tag them.
            </p>

            <p>
              Secondly, we switched from the outdated YoloV5 to the up-to-date
              YoloV8 which is supposedly better in every single way. We chose
              the small version, because the larger the model, the slower
              inference is, and while performance doesn’t really matter when
              training, one can simply leave their computer running while they
              are not home, it is still vital during inference, because our
              laptops are not on par with our workstations at home.
            </p>

            <p>
              To use our model, we wrote a script named kokanyrecognize at the
              last minute. It wasn’t very performant nor really clean, so we
              spent a significant amount of time working on it. So far it was
              rewritten to use the new model, however it still has a long way to
              go.
            </p>
            <p>Here is the result so far:</p>
            <img
              src="./img/inference.jpg"
              alt="Image showcasing the accuracy of our model"
            />
          </div>
          <div class="communication">
            <h2>4.2 Communication</h2>
            <p>
              We interact with our robot using a few custom programs, named
              KókányControl (kokanyctl) and KókányRecognize (kokanyrecognize).
            </p>
            <p>
              KókányControl has a graphical interface for displaying the video
              and the sensor data it receives from Kókánybot. It takes keyboard
              input, and sends commands to the Raspberry Pi. It also recognizes
              QR codes that appear on Kókánybot’s cameras.
            </p>
            <p>
              KókányRecognize was written to reduce the complexity of
              KókányControl, since image recognition functionality is only
              needed in a few runs, and we can just launch KókányRecognize
              whenever we need it. This also enabled us to build KókányControl
              in pure C, since we would have needed to use C++ to build the
              image recognition bits (which uses OpenCV).
            </p>
            <h2>Video and audio streaming</h2>
            <p>
              During tests, operators are only allowed to see the arenas from
              their robot’s point of view. This meant we needed a way to find a
              way to display the video data from the robot’s cameras.
            </p>
            <p>
              We've learnt from our mistakes last year, and have opted for using
              multiple cameras so that we have better peripheral vision while
              controlling Kókánybot.
            </p>
            <p>
              Multimedia related tasks are surprisingly computation heavy when
              one is working with embedded systems. The CPU in the Raspberry Pi
              4B+ is fairly capable, however we also had to consider power draw
              and thermal related problems. We considered several video formats:
              H.265, AV1 and H.264, but in the end we settled on using raw
              frames from our cameras to minimize latency as much as possible,
              since at the 2023 RoboCup, our camera's high latency caused a lot
              of trouble.
            </p>
            <p>
              One of our cameras is currently a
              <a
                href="https://www.raspberrypi.com/documentation/accessories/camera.html"
                >Raspberry Pi Official Camera Module</a
              >. This uses the new and improved libcamera stack which does not
              play well with regular V4L2 programs—such as FFmpeg—hence we wrote
              a
              <a
                href="https://github.com/zsoltiv/kokanybot/blob/master/kokanystream-front.sh"
                >modified script</a
              >
              to work with the Pi Camera.
            </p>
            <p>
              Linux assigns <code>/dev/videoN</code> to every camera. Since our
              cameras have to be handled by separate programs, and have
              different output formats, we must be able to tell them apart in a
              consistent way. Linux provides a way to do this using
              <a href="https://en.wikipedia.org/wiki/Udev">udev</a> rules. We
              gathered the attributes of the cameras using
              <code>udevadm</code>—a standard udev utility—and
              <a
                href="https://github.com/zsoltiv/kokanybot/blob/master/rules/60-camera.rules"
                >wrote rules</a
              >
              to assign the <code>/dev/front-camera</code> and
              <code>/dev/rear-camera</code>
              names to our cameras.
            </p>
            <p>
              On the client side, we implemented the decoding of the video data
              using FFmpeg’s libavformat and libavcodec libraries. Rendering the
              video frames was tricky to figure out because pretty much all
              video encoders store pixels in YCbCr colour space, which SDL isn’t
              the best for.
            </p>
            <p>
              The APIs of the libav* libraries are <i>huge</i>. Thankfully we
              only really needed the
              <a
                href="https://ffmpeg.org/doxygen/trunk/group__lavc__encdec.html"
                target="_blank"
                >high level decoding API</a
              >. The
              <a
                href="https://github.com/namndev/FFmpegTutorial/blob/master/learn-ffmpeg-libav-the-hard-way.md"
                target="_blank"
                >Learn FFmpeg libav the Hard Way</a
              >
              tutorial combined with the
              <a
                href="https://git.ffmpeg.org/gitweb/ffmpeg.git/tree/HEAD:/doc/examples"
                target="_blank"
                >examples</a
              >
              in the project's documentation also made things much easier.
            </p>
          </div>
          <div class="humanrobot">
            <h2>4.3 Human-robot interface</h2>
            <p>Still thinkking</p>
          </div>
        </div>
        <div class="hardware">
          <h1>Hardware</h1>
          <div class="setup">
            <h2>5.1 Setup and packing, operation station</h2>
          </div>
          <div class="strategy">
            <h2>5.2 Mission strategy</h2>
          </div>
          <div class="test">
            <h2>5.3 Tests and experiments</h2>
          </div>
          <div class="strength">
            <h2>5.4 Strenght of the robot on the field</h2>
          </div>
          <div class="build">
            <h2>5.5 The build and the development process of the robot.</h2>
          </div>
        </div>
        <div class="learned">
          <h1>6. What we learned so far</h1>
          <p></p>
        </div>
        <div class="until">
          <h1>7. What are we gonna do until the competition</h1>
          <p>
            We are facing an upcoming "event" in our life. In our country this
            time of the year amd age all highschool student will be attending a
            examination which will decide our future. Preparing to the
            competition and at the same time studying to the upcoming test is
            very hard so we are trying to devide our time accordingly. Of course
            we want to get better grades and points from the exam as well as to
            test more and more on the robot for the smallest gaps that could
            accour on the competition.
          </p>
        </div>
        <div class="source">
          <h1>8. Software packeges and hardware components</h1>
          <div class="softpackeges">
            <h2>8.1 Software packeges</h2>
            <table>
              <tbody>
                <tr class="odd">
                  <td>
                    <a
                      href="https://git.kernel.org/pub/scm/libs/libgpiod/libgpiod.git/about/"
                      target="_blank"
                    >
                      libgpiod
                    </a>
                  </td>
                  <td>DC motor control, sensor control, stepper control</td>
                </tr>
                <tr class="even">
                  <td>
                    <a href="https://opencv.org/" target="_blank"> OpenCV </a>
                  </td>
                  <td>Image recognition</td>
                </tr>
                <tr class="odd">
                  <td>
                    <a href="https://ffmpeg.org/" target="_blank"> FFmpeg </a>
                  </td>
                  <td>
                    Video streaming, Image recognition backend (used by OpenCV)
                  </td>
                </tr>
                <tr class="even">
                  <td>
                    <a href="https://www.libsdl.org/" target="_blank"> SDL2 </a>
                  </td>
                  <td>
                    Used by KókányControl to process keyboard input and display
                    video
                  </td>
                </tr>
                <tr class="odd">
                  <td>
                    <a
                      href="https://github.com/libsdl-org/SDL_ttf"
                      target="_blank"
                    >
                      SDL2_ttf
                    </a>
                  </td>
                  <td>
                    Used by KókányControl to draw text for displaying sensor
                    data
                  </td>
                </tr>
                <tr class="even">
                  <td>
                    <a
                      href="https://github.com/libsdl-org/SDL_net"
                      target="_blank"
                    >
                      SDL2_net
                    </a>
                  </td>
                  <td>Used by KókányControl to handle networking</td>
                </tr>
                <tr class="odd">
                  <td>
                    <a href="https://zbar.sourceforge.net/" target="_blank">
                      libzbar
                    </a>
                  </td>
                  <td>Used for QR code detection</td>
                </tr>
                <tr class="even">
                  <td>
                    <a
                      href="https://github.com/ultralytics/ultralytics"
                      target="_blank"
                    >
                      YoloV8 (small)
                    </a>
                  </td>
                  <td>The model we use for object detection</td>
                </tr>
                <tr class="even">
                  <td>
                    <a
                      href="https://universe.roboflow.com/new-workspace-xqnz7/rmrc-dqa9p"
                      target="_blank"
                    >
                      RMRC Dataset
                    </a>
                  </td>
                  <td>Dataset used for training our image recognition model</td>
                </tr>
                <tr class="odd">
                  <td>
                    <a href="https://undefined-medium.com/" target="_blank">
                      undefined medium
                    </a>
                  </td>
                  <td>The font used in kokanyctl</td>
                </tr>
                <tr class="even">
                  <td>
                    <a
                      href="https://github.com/zsoltiv/libhwpwm/tree/master"
                      target="_blank"
                    >
                      libhwpwm
                    </a>
                  </td>
                  <td>
                    A C library to interface with the
                    <a
                      href="https://www.kernel.org/doc/html/latest/driver-api/pwm.html#using-pwms-with-the-sysfs-interface"
                    >
                      Linux PWM userspace API
                    </a>
                  </td>
                </tr>
                <tr class="odd">
                  <td>
                    <a
                      href="https://github.com/raspberrypi/rpicam-apps"
                      target="_blank"
                    >
                      rpicam-apps
                    </a>
                  </td>
                  <td>
                    The programs used to capture the Pi Camera's video data
                  </td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="hardwareComponents">
            <h2>8.2 hardware Components and estimated prices</h2>
            <table id="partlist">
              <tbody>
                <tr>
                  <th>Component</th>
                  <th>Cost (in Euros)</th>
                </tr>
                <tr>
                  <td>Raspberry Pi 4B+</td>
                  <td>71</td>
                </tr>
                <tr>
                  <td>4x JGA25-370 12V 60rpm</td>
                  <td>34.58</td>
                </tr>
                <tr>
                  <td>Parkside X20V Drill Battery</td>
                  <td>42.16</td>
                </tr>
                <tr>
                  <td>DCDC-6010-M, DC/DC step-down, max. 60V, max. 10A</td>
                  <td>17</td>
                </tr>
                <tr>
                  <td>Webcamera</td>
                  <td>26.78</td>
                </tr>
                <tr>
                  <td>2x LT-623</td>
                  <td>4.23</td>
                </tr>
                <tr>
                  <td>2kg PLA filament for 3D prints</td>
                  <td>40.5</td>
                </tr>
                <tr>
                  <td>4x Tower Pro MG995</td>
                  <td>32</td>
                </tr>
                <tr>
                  <td>Adafruit PCA9685 servo controller</td>
                  <td>13,77</td>
                </tr>
                <tr>
                  <td>6-24V 12V/24V to 5V 3A CAR USB Charger Modul</td>
                  <td>3</td>
                </tr>
                <tr>
                  <td>AX SS HYRAX crawler tire 120mm diameter 4pc pack</td>
                  <td>30,52</td>
                </tr>
                <tr>
                <tr>
                <tr>
                  <td>Overall cost of components</td>
                  <td id="totalcost"></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
    <script src="script.js"></script>
  </body>
</html>
